from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration, Trainer, TrainingArguments
import os

MODEL_DIR = "models/rag_finetuned/"

class RAGFineTuner:
    def __init__(self):
        """Loads pre-trained RAG model and tokenizer."""
        self.tokenizer = RagTokenizer.from_pretrained("facebook/rag-token-nq")
        self.retriever = RagRetriever.from_pretrained("facebook/rag-token-nq", index_name="exact")
        self.model = RagSequenceForGeneration.from_pretrained("facebook/rag-token-nq")

    def fine_tune(self, train_dataset):
        """Fine-tunes RAG model using provided dataset."""
        training_args = TrainingArguments(
            output_dir=MODEL_DIR,
            per_device_train_batch_size=2,
            evaluation_strategy="epoch",
            save_total_limit=1,
            num_train_epochs=3,
            save_steps=500,
            logging_steps=100
        )

        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset
        )

        trainer.train()

        # Save fine-tuned model
        self.model.save_pretrained(MODEL_DIR)
        self.tokenizer.save_pretrained(MODEL_DIR)
        print(f"âœ… Fine-tuned model saved in {MODEL_DIR}")

if __name__ == "__main__":
    # TODO: Replace `train_dataset=None` with a real dataset
    fine_tuner = RAGFineTuner()
    fine_tuner.fine_tune(train_dataset=None)
